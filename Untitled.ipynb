{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c32f507-9992-475a-b840-3fe61742f838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data from videos_2013.csv\n",
      "Read data from videos_2014.csv\n",
      "Read data from videos_2015.csv\n",
      "Read data from videos_2016.csv\n",
      "Read data from videos_2017.csv\n",
      "Read data from videos_2018.csv\n",
      "Read data from videos_2019.csv\n",
      "Read data from videos_2020.csv\n",
      "Read data from videos_2021.csv\n",
      "Read data from videos_2022.csv\n",
      "Read data from videos_2023.csv\n",
      "Combined data exported to combined_videos.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path to the resource folder where the CSV files are located\n",
    "resource_folder = 'Resources'\n",
    "\n",
    "# Initialize an empty list to store the DataFrames from each year\n",
    "dataframes = []\n",
    "\n",
    "# Create a list of file names for each year\n",
    "years = range(2013, 2024)\n",
    "csv_files = [f'videos_{year}.csv' for year in years]\n",
    "\n",
    "# Read each CSV file and append the DataFrame to the list\n",
    "for csv_file in csv_files:\n",
    "    # Construct the full file path\n",
    "    file_path = os.path.join(resource_folder, csv_file)\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Append the DataFrame to the list\n",
    "    dataframes.append(df)\n",
    "    print(f'Read data from {csv_file}')\n",
    "\n",
    "# Concatenate all DataFrames into one DataFrame\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Export the combined DataFrame to a single CSV file\n",
    "output_file_path = 'combined_videos.csv'\n",
    "combined_df.to_csv(output_file_path, index=False)\n",
    "print(f'Combined data exported to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afc8287c-335c-40d3-b509-8894ad7a35d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              1485\n",
       "published_at    1485\n",
       "length          1485\n",
       "views           1485\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()\n",
    "combined_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d43be86-9d46-43fe-a97b-97ff9a95b029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, published_at, length, views]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "rows_with_na = combined_df[combined_df['views'].isna()]\n",
    "\n",
    "# Print the rows with 'N/A' or empty values in the 'views' column\n",
    "print(rows_with_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82f47746-ac0d-46dd-ac3f-33caa7883d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id          published_at   length       views length_minutes\n",
      "0     pjAJswDB14s  2013-11-08T20:03:07Z   PT1M3S    145004.0              1\n",
      "1     qMkYlIA7mgw  2013-06-05T21:35:43Z  PT4M42S  26994739.0              4\n",
      "2     T8WpJlaZNZI  2013-11-08T20:12:12Z   PT1M4S     34840.0              1\n",
      "3     KfWNOnns1FM  2013-10-10T08:29:45Z  PT4M18S      1814.0              4\n",
      "4     81pvnaj3EI4  2013-11-08T20:15:38Z    PT36S     34449.0            NaN\n",
      "...           ...                   ...      ...         ...            ...\n",
      "2441  f2LFo3t8rGQ  2023-06-05T17:26:47Z    PT29S     30920.0            NaN\n",
      "2443  j8v2xQfF2BQ  2023-12-18T06:35:00Z     PT6S      5716.0            NaN\n",
      "2444  iCog3FfNGI4  2023-06-06T13:35:00Z    PT10S     19399.0            NaN\n",
      "2445  UEC2Q8oTDDA  2023-10-22T09:05:00Z     PT7S     13747.0            NaN\n",
      "2446  1G3c0j4UnLc  2023-05-23T00:42:23Z    PT27S     41675.0            NaN\n",
      "\n",
      "[1381 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame to keep rows where the 'length' column is not equal to 'P0D'\n",
    "cleaned_df = combined_df[combined_df['length'] != 'P0D']\n",
    "\n",
    "rows_with_na = combined_df[combined_df['length'].isna()]\n",
    "\n",
    "# Print the cleaned DataFrame (optional)\n",
    "print(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "950c76c8-b6aa-4a22-83e5-76cb0e87669c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data exported to cleaned_videos.csv\n"
     ]
    }
   ],
   "source": [
    "output_file_path = 'cleaned_videos.csv'\n",
    "cleaned_df.to_csv(output_file_path, index=False)\n",
    "print(f'Cleaned data exported to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acb9db26-5bba-4d08-b7f3-fdd7bfbbb94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id          published_at   length       views  length_minutes  \\\n",
      "0  pjAJswDB14s  2013-11-08T20:03:07Z   PT1M3S    145004.0             1.0   \n",
      "1  qMkYlIA7mgw  2013-06-05T21:35:43Z  PT4M42S  26994739.0             4.0   \n",
      "2  T8WpJlaZNZI  2013-11-08T20:12:12Z   PT1M4S     34840.0             1.0   \n",
      "3  KfWNOnns1FM  2013-10-10T08:29:45Z  PT4M18S      1814.0             4.0   \n",
      "4  81pvnaj3EI4  2013-11-08T20:15:38Z    PT36S     34449.0             0.0   \n",
      "\n",
      "   length_seconds  length_seconds_total  \n",
      "0             3.0                  63.0  \n",
      "1            42.0                 282.0  \n",
      "2             4.0                  64.0  \n",
      "3            18.0                 258.0  \n",
      "4            36.0                  36.0  \n"
     ]
    }
   ],
   "source": [
    "# Use a regular expression to extract minutes and seconds from the 'length' column\n",
    "combined_df[['length_minutes', 'length_seconds']] = combined_df['length'].str.extract(r'PT(?:(\\d+)M)?(?:(\\d+)S)?')\n",
    "\n",
    "# Convert the extracted values to numeric (floats)\n",
    "combined_df['length_minutes'] = pd.to_numeric(combined_df['length_minutes'], errors='coerce').fillna(0)\n",
    "combined_df['length_seconds'] = pd.to_numeric(combined_df['length_seconds'], errors='coerce').fillna(0)\n",
    "\n",
    "# Calculate the total length in seconds\n",
    "combined_df['length_seconds_total'] = (combined_df['length_minutes'] * 60) + combined_df['length_seconds']\n",
    "\n",
    "# Print the first few rows to verify the changes\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c89ace6-5dfd-46e5-987a-ac1f161923bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id              published_at   length       views  length_minutes  \\\n",
      "0  pjAJswDB14s 2013-11-08 20:03:07+00:00   PT1M3S    145004.0             1.0   \n",
      "1  qMkYlIA7mgw 2013-06-05 21:35:43+00:00  PT4M42S  26994739.0             4.0   \n",
      "2  T8WpJlaZNZI 2013-11-08 20:12:12+00:00   PT1M4S     34840.0             1.0   \n",
      "3  KfWNOnns1FM 2013-10-10 08:29:45+00:00  PT4M18S      1814.0             4.0   \n",
      "4  81pvnaj3EI4 2013-11-08 20:15:38+00:00    PT36S     34449.0             0.0   \n",
      "\n",
      "   length_seconds  length_seconds_total  year  \n",
      "0             3.0                  63.0  2013  \n",
      "1            42.0                 282.0  2013  \n",
      "2             4.0                  64.0  2013  \n",
      "3            18.0                 258.0  2013  \n",
      "4            36.0                  36.0  2013  \n"
     ]
    }
   ],
   "source": [
    "# Convert the 'published_at' column to datetime data type\n",
    "combined_df['published_at'] = pd.to_datetime(combined_df['published_at'])\n",
    "\n",
    "# Extract the year from the 'published_at' column\n",
    "combined_df['year'] = combined_df['published_at'].dt.year\n",
    "\n",
    "# Print the first few rows to verify the changes\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36a2536c-e78c-4077-b9a1-f9968481fc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID  Year  View Count  Length (s)\n",
      "0  pjAJswDB14s  2013    145004.0        63.0\n",
      "1  qMkYlIA7mgw  2013  26994739.0       282.0\n",
      "2  T8WpJlaZNZI  2013     34840.0        64.0\n",
      "3  KfWNOnns1FM  2013      1814.0       258.0\n",
      "4  81pvnaj3EI4  2013     34449.0        36.0\n"
     ]
    }
   ],
   "source": [
    "data_df = combined_df[['id', 'year', 'views', 'length_seconds_total']]\n",
    "data_df = data_df.rename(columns={\n",
    "    'id': 'ID',\n",
    "    'year': 'Year',\n",
    "    'views': 'View Count',\n",
    "    'length_seconds_total': 'Length (s)'\n",
    "})\n",
    "\n",
    "print(data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28500f5e-dca1-49e2-8d30-f6f258bba730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
