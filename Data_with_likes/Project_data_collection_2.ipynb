{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d32a9705-2c36-495a-a5c9-6c497190c66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 194 videos for the year 2019\n",
      "Fetched 155 videos for the year 2020\n",
      "Fetched 160 videos for the year 2021\n",
      "Fetched 225 videos for the year 2022\n",
      "Fetched 196 videos for the year 2023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2019:               id          published_at    views   likes  dislikes  comments  \\\n",
       " 0    SumDHcnCRuU  2019-10-30T11:15:00Z  8752785  249401         0     11035   \n",
       " 1    J1Yv24cM2os  2019-03-10T15:17:38Z  6004648  154414         0     13352   \n",
       " 2    lBCcmedmbhM  2019-01-11T21:43:02Z  2112655   35947         0      1208   \n",
       " 3    0LS0Z8fgiII  2019-07-20T17:58:46Z  6020587   74426         0      3310   \n",
       " 4    B3C6XVjpSJ4  2019-07-17T22:05:07Z  2468658   39187         0      2542   \n",
       " ..           ...                   ...      ...     ...       ...       ...   \n",
       " 189  rBdV1iam5Ts  2019-03-03T05:54:10Z     6098      63         0         6   \n",
       " 190  aDYZuHLfQmw  2019-04-30T02:00:01Z   752581    4366         0        87   \n",
       " 191  NSBabkVHeNE  2019-07-18T06:10:22Z  1587105    5293         0       105   \n",
       " 192  79UGt02ow5o  2019-02-22T22:25:47Z     3584      65         0        11   \n",
       " 193  4LomZbNJnZQ  2019-03-16T02:30:00Z  5163034   24660         0       526   \n",
       " \n",
       "        length  \n",
       " 0     PT3M15S  \n",
       " 1     PT3M47S  \n",
       " 2      PT2M4S  \n",
       " 3     PT3M30S  \n",
       " 4     PT2M26S  \n",
       " ..        ...  \n",
       " 189     PT55S  \n",
       " 190   PT4M43S  \n",
       " 191   PT6M48S  \n",
       " 192   PT2M57S  \n",
       " 193  PT13M20S  \n",
       " \n",
       " [194 rows x 7 columns],\n",
       " 2020:               id          published_at     views   likes  dislikes  comments  \\\n",
       " 0    742rjaRrGXU  2020-05-27T04:40:42Z    253925    5265         0       315   \n",
       " 1    JjmX_PLgovk  2020-10-21T07:40:42Z   2718290  182789         0       987   \n",
       " 2    hMDsmKRO8YI  2020-02-29T20:07:18Z  10985911  199213         0     13994   \n",
       " 3    cbIsdtIi4Sw  2020-09-08T16:48:17Z   1052603   10564         0       709   \n",
       " 4    COmW6r23zas  2020-07-10T18:00:11Z   2982726   96766         0      3786   \n",
       " ..           ...                   ...       ...     ...       ...       ...   \n",
       " 150  yW2QVcBMCWI  2020-09-11T14:23:36Z      1207       0         0         0   \n",
       " 151  2_Z0OhUXJ_k  2020-09-24T03:48:49Z       894       0         0         0   \n",
       " 152  GroK1V8Oz1Y  2020-09-01T10:40:42Z     47215    2332         0         0   \n",
       " 153  uQF6PVLHthU  2020-08-30T12:54:47Z    595314    1853         0         7   \n",
       " 154  Hiu1HwWrRm4  2020-08-14T12:00:11Z     18185     430         0        31   \n",
       " \n",
       "       length  \n",
       " 0    PT4M47S  \n",
       " 1      PT45S  \n",
       " 2     PT2M3S  \n",
       " 3    PT2M25S  \n",
       " 4    PT4M31S  \n",
       " ..       ...  \n",
       " 150    PT43S  \n",
       " 151    PT31S  \n",
       " 152    PT16S  \n",
       " 153  PT5M50S  \n",
       " 154   PT3M3S  \n",
       " \n",
       " [155 rows x 7 columns],\n",
       " 2021:               id          published_at      views    likes  dislikes  \\\n",
       " 0    mFEKmmGZCxg  2021-11-13T05:54:59Z    9527162   563950         0   \n",
       " 1    -FBwZtuJtMw  2021-05-10T21:35:40Z    3338031   246751         0   \n",
       " 2    kzkChigcPTw  2021-12-18T17:22:13Z      16632     1396         0   \n",
       " 3    4kptlrzcCfc  2021-10-12T16:52:39Z   22215672  1694199         0   \n",
       " 4    SBaIxNCV4KU  2021-12-13T03:26:05Z    8104332   647622         0   \n",
       " ..           ...                   ...        ...      ...       ...   \n",
       " 155  LA-XLvoEUxM  2021-12-01T17:47:31Z    2941490    87432         0   \n",
       " 156  OeKk9R95vr0  2021-03-01T08:50:39Z  135224537   872082         0   \n",
       " 157  cnN56tUFPtQ  2021-12-18T14:56:53Z     346300    20003         0   \n",
       " 158  ENyK1AqBL7s  2021-12-27T22:25:35Z     380907    33544         0   \n",
       " 159  Nn8cpcPUlBs  2021-11-30T12:45:22Z     248099    13018         0   \n",
       " \n",
       "      comments   length  \n",
       " 0        2260    PT49S  \n",
       " 1       18812  PT3M30S  \n",
       " 2          20    PT36S  \n",
       " 3       50250    PT11S  \n",
       " 4       42500    PT55S  \n",
       " ..        ...      ...  \n",
       " 155        77    PT45S  \n",
       " 156      2475    PT18S  \n",
       " 157        34    PT37S  \n",
       " 158      2480    PT55S  \n",
       " 159        93    PT34S  \n",
       " \n",
       " [160 rows x 7 columns],\n",
       " 2022:               id          published_at     views    likes  dislikes  comments  \\\n",
       " 0    Rg3Xi5MwfGI  2022-04-19T15:00:22Z   1169531     1865         0       118   \n",
       " 1    6sOfeklOHnY  2022-01-29T05:45:00Z   1653591   143645         0       320   \n",
       " 2    WpGrl1-GZMA  2022-01-14T21:30:05Z  10827031   714097         0      1879   \n",
       " 3    jPAR4KAajVY  2022-04-01T22:30:06Z  14151503   957730         0      1386   \n",
       " 4    NwU4gd_kLbQ  2022-09-23T01:36:24Z  80522310  3619916         0      2193   \n",
       " ..           ...                   ...       ...      ...       ...       ...   \n",
       " 220  OhiNK5YaBh0  2022-01-13T06:50:50Z      1805        0         0         0   \n",
       " 221  OMTHa8TMEIk  2022-06-06T10:00:13Z       860       35         0         0   \n",
       " 222  WJiSgZduc-I  2022-09-07T03:30:16Z    455916     2379         0        71   \n",
       " 223  flMlEB7aLho  2022-11-11T17:00:26Z   7750577        0         0       798   \n",
       " 224  QPiDgU7ixhs  2022-02-20T14:08:51Z    987795    20377         0      1329   \n",
       " \n",
       "        length  \n",
       " 0      PT2M3S  \n",
       " 1       PT41S  \n",
       " 2       PT39S  \n",
       " 3       PT43S  \n",
       " 4       PT33S  \n",
       " ..        ...  \n",
       " 220     PT13S  \n",
       " 221     PT47S  \n",
       " 222    PT3M5S  \n",
       " 223     PT41S  \n",
       " 224  PT14M34S  \n",
       " \n",
       " [225 rows x 7 columns],\n",
       " 2023:               id          published_at      views    likes  dislikes  \\\n",
       " 0    1qIEW93kH8Y  2023-06-15T12:06:58Z   55605676  1072045         0   \n",
       " 1    oAGow4FpWQw  2023-06-08T18:03:56Z  173967071  2803249         0   \n",
       " 2    lWdM-2paUF8  2023-06-06T16:30:09Z   53336582   559591         0   \n",
       " 3    v-m9SU9kShE  2023-06-03T09:36:53Z   57944478   908147         0   \n",
       " 4    tYpfVvx4rvY  2023-05-04T15:00:41Z   34805603   451943         0   \n",
       " ..           ...                   ...        ...      ...       ...   \n",
       " 191  DddkCe6rbss  2023-01-07T20:23:41Z     304560    39402         0   \n",
       " 192  Kjn-Wqf6FHU  2023-05-08T03:41:08Z     229929    12675         0   \n",
       " 193  uBaRzq-0i6M  2023-04-22T21:39:57Z      56071     3017         0   \n",
       " 194  Znh-Szp1sac  2023-01-26T22:30:41Z      99991     7058         0   \n",
       " 195  bbogtnHCEjo  2023-03-24T20:07:21Z     169937    11665         0   \n",
       " \n",
       "      comments  length  \n",
       " 0         977   PT16S  \n",
       " 1       16169   PT13S  \n",
       " 2         701   PT10S  \n",
       " 3           0   PT29S  \n",
       " 4           0   PT15S  \n",
       " ..        ...     ...  \n",
       " 191       289   PT58S  \n",
       " 192        66   PT19S  \n",
       " 193        26  PT1M1S  \n",
       " 194        33   PT32S  \n",
       " 195        71   PT18S  \n",
       " \n",
       " [196 rows x 7 columns]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Replace 'YOUR_API_KEY' with your actual API key.\n",
    "api_key = 'Your key'\n",
    "\n",
    "# Create the YouTube service using the API key\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "def get_videos_from_year(year, num_videos):\n",
    "    # Calculate the date range for the given year\n",
    "    published_after = f'{year}-01-01T00:00:00Z'\n",
    "    published_before = f'{year + 1}-01-01T00:00:00Z'\n",
    "    \n",
    "    # Initialize a list to store the videos\n",
    "    videos = []\n",
    "\n",
    "    # Keep track of the next page token for pagination\n",
    "    next_page_token = None\n",
    "\n",
    "    # Retrieve up to `num_videos` videos from the given year\n",
    "    while len(videos) < num_videos:\n",
    "        # Use the search.list() method to search for videos within the date range\n",
    "        search_request = youtube.search().list(\n",
    "            part='id,snippet',\n",
    "            type='video',\n",
    "            publishedAfter=published_after,\n",
    "            publishedBefore=published_before,\n",
    "            maxResults=50,  # Maximum number of results per request (up to 50)\n",
    "            pageToken=next_page_token  # Use the next page token for pagination\n",
    "        )\n",
    "        \n",
    "        # Execute the search request and get the response\n",
    "        search_response = search_request.execute()\n",
    "        \n",
    "        # Extract video IDs and publication dates from the search results\n",
    "        video_ids = []\n",
    "        for item in search_response['items']:\n",
    "            video_id = item['id']['videoId']\n",
    "            published_at = item['snippet']['publishedAt']\n",
    "            videos.append({'id': video_id, 'published_at': published_at})\n",
    "            video_ids.append(video_id)\n",
    "        \n",
    "        # Use the videos.list() method to retrieve details about the videos\n",
    "        if video_ids:\n",
    "            video_request = youtube.videos().list(\n",
    "                part='contentDetails,statistics',\n",
    "                id=','.join(video_ids)\n",
    "            )\n",
    "            \n",
    "            # Execute the video request and get the response\n",
    "            video_response = video_request.execute()\n",
    "            \n",
    "            # Add length, views, likes, dislikes, and comments to the videos list\n",
    "            for video in video_response['items']:\n",
    "                # Find the video in the list by ID and update its information\n",
    "                for video_info in videos:\n",
    "                    if video_info['id'] == video['id']:\n",
    "                        # Retrieve and convert views, likes, dislikes, and comments to integers\n",
    "                        views = int(video['statistics'].get('viewCount', 0))\n",
    "                        likes = int(video['statistics'].get('likeCount', 0))\n",
    "                        dislikes = int(video['statistics'].get('dislikeCount', 0))\n",
    "                        comments = int(video['statistics'].get('commentCount', 0))\n",
    "                        \n",
    "                        # Retrieve length (duration) in ISO 8601 format\n",
    "                        length = video['contentDetails'].get('duration')\n",
    "                        \n",
    "                        # Only add videos with non-zero views and valid length\n",
    "                        if views > 0 and length:\n",
    "                            video_info['views'] = views\n",
    "                            video_info['likes'] = likes\n",
    "                            video_info['dislikes'] = dislikes\n",
    "                            video_info['comments'] = comments\n",
    "                            video_info['length'] = length\n",
    "                        else:\n",
    "                            # Remove video_info if it doesn't meet criteria\n",
    "                            videos.remove(video_info)\n",
    "        \n",
    "        # Get the next page token for pagination\n",
    "        next_page_token = search_response.get('nextPageToken')\n",
    "        \n",
    "        # If there are no more pages, break out of the loop\n",
    "        if not next_page_token:\n",
    "            break\n",
    "    \n",
    "    # Return the list of videos (limited to `num_videos`)\n",
    "    return videos[:num_videos]\n",
    "\n",
    "# Define the range of years you want to retrieve videos from\n",
    "years = range(2019, 2024)\n",
    "\n",
    "# Initialize a dictionary to store the DataFrames for each year\n",
    "videos_by_year_df = {}\n",
    "\n",
    "# Retrieve 500 videos from each year in the specified range and convert to DataFrame\n",
    "for year in years:\n",
    "    videos = get_videos_from_year(year, 500)\n",
    "    # Convert the list of videos to a pandas DataFrame\n",
    "    df = pd.DataFrame(videos)\n",
    "    # Store the DataFrame in the dictionary\n",
    "    videos_by_year_df[year] = df\n",
    "    print(f'Fetched {len(df)} videos for the year {year}')\n",
    "\n",
    "# Output the dictionary of DataFrames\n",
    "videos_by_year_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a32271-2cb4-4be6-8792-aeb67922bbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 214 videos for the year 2019\n",
      "DataFrame for year 2019 exported to videos_2019.csv\n",
      "Fetched 152 videos for the year 2020\n",
      "DataFrame for year 2020 exported to videos_2020.csv\n",
      "Fetched 227 videos for the year 2021\n",
      "DataFrame for year 2021 exported to videos_2021.csv\n",
      "Fetched 150 videos for the year 2022\n",
      "DataFrame for year 2022 exported to videos_2022.csv\n",
      "Fetched 195 videos for the year 2023\n",
      "DataFrame for year 2023 exported to videos_2023.csv\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    videos = get_videos_from_year(year, 500)\n",
    "    # Convert the list of videos to a pandas DataFrame\n",
    "    df = pd.DataFrame(videos)\n",
    "    # Store the DataFrame in the dictionary\n",
    "    videos_by_year_df[year] = df\n",
    "    print(f'Fetched {len(df)} videos for the year {year}')\n",
    "    \n",
    "    # Export the DataFrame to a CSV file\n",
    "    file_path = f'videos_{year}.csv'\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f'DataFrame for year {year} exported to {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb94db3-e1d8-4eab-8057-dbea8875f201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac632822-c257-44ac-90fc-b597e9c2e8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
